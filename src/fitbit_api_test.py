import requests
import json
import os
import base64
from dotenv import load_dotenv
from google.cloud import bigquery
from datetime import datetime
from dateutil import parser

# .env ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
CLIENT_ID = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")

# ãƒˆãƒ¼ã‚¯ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
TOKEN_URL = "https://api.fitbit.com/oauth2/token"

def get_basic_auth_header(client_id, client_secret):
    """
    Client ID ã¨ Client Secret ã‚’ Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸèªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ
    """
    auth_str = f"{client_id}:{client_secret}"
    auth_bytes = auth_str.encode("utf-8")
    auth_base64 = base64.b64encode(auth_bytes).decode("utf-8")
    return f"Basic {auth_base64}"

def load_tokens():
    """
    tokens.jsonãŒå­˜åœ¨ã™ã‚‹ãªã‚‰ã€ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã¨ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ‰‹ã«å…¥ã‚Œã‚‹
    """
    if os.path.exists("tokens.json"):
        with open("tokens.json", "r") as f:
            tokens = json.load(f)
        return tokens.get("access_token"), tokens.get("refresh_token")
    return None, None

def save_tokens(tokens):
    """
    tokens.jsonã‚’é–‹ã„ã¦ã€jsonå½¢å¼ã§ä¸Šæ›¸ãã™ã‚‹
    """
    with open("tokens.json", "w") as f:
        json.dump(tokens, f, indent=2)

def refresh_access_token(refresh_token):
    """
    ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ã£ã¦æ–°ã—ã„ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
    """
    headers = {
        "Authorization": get_basic_auth_header(CLIENT_ID, CLIENT_SECRET),
        "Content-Type": "application/x-www-form-urlencoded"
    }

    data = {
        "grant_type": "refresh_token",
        "refresh_token": refresh_token
    }

    response = requests.post(TOKEN_URL, headers=headers, data=data)

    if response.status_code == 200:
        tokens = response.json()
        print("âœ… æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã¾ã—ãŸ:")
        #print(json.dumps(tokens, indent=2))

        # å¿…è¦ã«å¿œã˜ã¦ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãªã©
        with open("tokens.json", "w") as f:
            json.dump(tokens, f, indent=2)

        return tokens["access_token"], tokens["refresh_token"]
    else:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
        print(response.text)
        return None, None

def call_api(access_token):
    """
    Fitbit APIã®å‘¼ã³å‡ºã—ã‚’è¡Œã†
    """
    api_url = "https://api.fitbit.com/1.2/user/-/sleep/date/2025-07-02/2025-07-20.json"
    headers = {
        "Authorization": f"Bearer {access_token}"
    }

    response = requests.get(api_url, headers=headers)
    if response.status_code == 200:
        print("âœ… API å‘¼ã³å‡ºã—æˆåŠŸ:")
        return response.json()
    elif response.status_code == 401:
        print("ğŸ” ãƒˆãƒ¼ã‚¯ãƒ³ãŒæœŸé™åˆ‡ã‚Œã€‚ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚")
        return "expired"
    else:
        print(f"âŒ API å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {response.status_code}")
        print(response.text)
        return None

def is_duplicate_log(client, table_id, sleep_log_id):
    """
    sleep_log_idã‚’é‡è¤‡ãƒã‚§ãƒƒã‚¯ã™ã‚‹
    """
    query = f"""
    SELECT COUNT(*) as count
    FROM `{table_id}`
    WHERE sleep_log_id = @log_id
    """
    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("log_id", "INT64", sleep_log_id)
        ]
    )
    query_job = client.query(query, job_config=job_config)
    results = query_job.result()
    return next(results).count > 0

def write_to_bigquery(bq_table,sleep_json):
    """
    bigqueryã«ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ã‚’è¡Œã†
    """
    client = bigquery.Client()
    table_id = bq_table

    job_config = bigquery.LoadJobConfig(
        autodetect=True,  # ã‚¹ã‚­ãƒ¼ãƒã‚’è‡ªå‹•åˆ¤åˆ¥
        schema=[
            bigquery.SchemaField("sleep_log_id", "INTEGER"),
            bigquery.SchemaField("date", "DATE"),
            bigquery.SchemaField("weekday", "STRING"),
            bigquery.SchemaField("startTime", "TIMESTAMP"),
            bigquery.SchemaField("endTime", "TIMESTAMP"),
            bigquery.SchemaField("minutesAsleep", "INTEGER"),
            bigquery.SchemaField("minutesAwake", "INTEGER"),
            bigquery.SchemaField("deep_minutes", "INTEGER"),
            bigquery.SchemaField("deep_sleep_ratio", "FLOAT"),
            bigquery.SchemaField("wake_count", "INTEGER"),
            bigquery.SchemaField("sleep_latency", "FLOAT"),
            bigquery.SchemaField("sleep_score", "INTEGER"),
            bigquery.SchemaField("timeInBed", "INTEGER"),
            bigquery.SchemaField("efficiency", "INTEGER"),
            bigquery.SchemaField("type", "STRING"),
            bigquery.SchemaField("is_main_sleep", "BOOLEAN"),
            bigquery.SchemaField("created_at", "TIMESTAMP"),
        ],
        write_disposition="WRITE_APPEND",  # è¿½è¨˜ï¼ˆåˆå›ã¯æ–°è¦ä½œæˆï¼‰
    )

    inserted_count = 0
    skipped_count = 0

    if "sleep" not in sleep_json or not sleep_json["sleep"]:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    rows = []
    for record in sleep_json["sleep"]:
        sleep_log_id = record.get("logId")
        if not is_duplicate_log(client, table_id, sleep_log_id):

            # å…¥çœ æ½œæ™‚ã‚’è¨ˆç®—
            start_dt = parser.parse(record["startTime"])

            sleep_stage_entries = [
                e for e in record.get("levels", {}).get("data", [])
                if e["level"] in ["asleep", "light", "deep", "rem"]
            ]

            if sleep_stage_entries:
                first_stage_dt = parser.parse(sleep_stage_entries[0]["dateTime"])
                start_dt = parser.parse(record["startTime"])
                sleep_latency = (first_stage_dt - start_dt).total_seconds() / 60
            else:
                sleep_latency = None
            print(sleep_latency)

            # æ·±ã„ç¡çœ æ™‚é–“ã¨å‰²åˆ
            minutes_asleep = record.get("minutesAsleep", 0)
            deep_minutes = record.get("levels", {}).get("summary", {}).get("deep", {}).get("minutes", 0)
            deep_sleep_ratio = (deep_minutes / minutes_asleep * 100) if minutes_asleep else None

            # èµ·åºŠå›æ•°
            wake_count = record.get("levels", {}).get("summary", {}).get("wake", {}).get("count")

            # æ›œæ—¥
            date_str = record.get("dateOfSleep")  # "2025-07-02" å½¢å¼
            date_obj = datetime.strptime(date_str, "%Y-%m-%d").date()
            weekday = date_obj.strftime("%A")  # "Monday"

            row = {
                "sleep_log_id": record.get("logId"),
                "date": record.get("dateOfSleep"),              # ç¡çœ è¨˜éŒ²æ—¥
                "weekday": weekday,                             # æ›œæ—¥
                "startTime": record.get("startTime"),           # ç¡çœ ã®é–‹å§‹æ™‚åˆ»
                "endTime": record.get("endTime"),               # ç¡çœ ã®çµ‚äº†æ™‚åˆ»
                "minutesAsleep": record.get("minutesAsleep"),   # å®Ÿéš›ã«çœ ã£ã¦ã„ãŸæ™‚é–“
                "minutesAwake": record.get("minutesAwake"),     # ãƒ™ãƒƒãƒ‰ã«ã„ãŸãŒå¯ã¦ã„ãªã‹ã£ãŸæ™‚é–“
                "deep_minutes": deep_minutes,                   # æ·±ã„ç¡çœ ã®åˆè¨ˆ
                "deep_sleep_ratio": deep_sleep_ratio,           # æ·±ã„ç¡çœ ã®å‰²åˆ
                "wake_count": wake_count,                       # ä¸­é€”è¦šé†’ã®å›æ•°
                "sleep_latency": sleep_latency,                 # å…¥åºŠã‹ã‚‰å…¥çœ ã¾ã§ã®æ™‚é–“
                "sleep_score": record.get("score"),             # Fitbitã®ç¡çœ ã‚¹ã‚³ã‚¢
                "timeInBed": record.get("timeInBed"),           # ãƒ™ãƒƒãƒ‰ã«ã„ãŸç·æ™‚é–“
                "efficiency": record.get("efficiency"),         # ç¡çœ åŠ¹ç‡(minutesAsleep/timeInBed)
                "type": record.get("type"),                     # ç¡çœ ã‚¹ãƒ†ãƒ¼ã‚¸
                "is_main_sleep": record.get("isMainSleep"),     # æœ¬ç¡çœ ãƒ•ãƒ©ã‚°
                "created_at": datetime.now().isoformat()
            }

            print(row)

            job = client.load_table_from_json([row], table_id, job_config=job_config)
            job.result()
            inserted_count += 1
        else:
            skipped_count += 1

    print("âœ… BigQuery ã«æ›¸ãè¾¼ã¿å®Œäº†")
    print(f"âœ… BigQuery æ›¸ãè¾¼ã¿å®Œäº†: è¿½åŠ  {inserted_count} ä»¶ / ã‚¹ã‚­ãƒƒãƒ— {skipped_count} ä»¶")

# ================== å®Ÿè¡Œéƒ¨åˆ† ==================
access_token, refresh_token = load_tokens()
bq_table = "fitbit-dashboard-463713.fitbit_data.sleep_data"

# APIã‚³ãƒ¼ãƒ«
result = call_api(access_token)

# ãƒˆãƒ¼ã‚¯ãƒ³æœŸé™åˆ‡ã‚Œãªã‚‰ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã—ã¦å†è©¦è¡Œ
if result == "expired":
    access_token, refresh_token = refresh_access_token(refresh_token)
    if access_token:
        result = call_api(access_token)

if result and result != "expired":
    write_to_bigquery(bq_table, result)